"""
ç«¶è¼ªãƒ‡ãƒ¼ã‚¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v2.1
- KEIRIN.JPï¼ˆå…¬å¼ã‚µã‚¤ãƒˆï¼‰å¯¾å¿œ
- æ¥½å¤©Kãƒ‰ãƒªãƒ¼ãƒ ã‚¹å¯¾å¿œ
- ã‚ªãƒƒã‚ºå–å¾—æ©Ÿèƒ½
- å¤©å€™ãƒ»é¢¨å‘ãå–å¾—
"""
import os
import time
import logging
import re
from datetime import datetime
from typing import Optional, Dict, List
from dataclasses import dataclass, field

import requests
from bs4 import BeautifulSoup
from tenacity import retry, stop_after_attempt, wait_exponential

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Racer:
    """é¸æ‰‹æƒ…å ±"""
    waku: int
    name: str
    racer_id: str = ""
    age: int = 0
    prefecture: str = ""
    rank: str = ""
    score: float = 0.0
    gear_ratio: str = ""
    comment: str = ""
    recent_results: List[str] = field(default_factory=list)


@dataclass
class LineFormation:
    """ãƒ©ã‚¤ãƒ³ç·¨æˆ"""
    line_members: List[int]
    strategy: str
    comment: str = ""


@dataclass
class OddsInfo:
    """ã‚ªãƒƒã‚ºæƒ…å ±"""
    sanrentan: Dict[str, float] = field(default_factory=dict)
    sanrenpuku: Dict[str, float] = field(default_factory=dict)
    nirentan: Dict[str, float] = field(default_factory=dict)
    nirenpuku: Dict[str, float] = field(default_factory=dict)
    wide: Dict[str, float] = field(default_factory=dict)


@dataclass
class WeatherInfo:
    """å¤©å€™æƒ…å ±"""
    weather: str = "æ™´"
    temperature: float = 20.0
    humidity: float = 50.0
    wind_direction: str = ""
    wind_speed: float = 0.0
    track_condition: str = "è‰¯"


@dataclass
class RaceInfo:
    """ãƒ¬ãƒ¼ã‚¹æƒ…å ±"""
    race_id: str
    velodrome: str
    velodrome_code: str
    race_number: int
    race_grade: str
    race_type: str
    distance: int
    bank_type: str
    racers: List[Racer]
    line_formations: List[LineFormation]
    race_datetime: datetime
    deadline: datetime
    weather: WeatherInfo = field(default_factory=WeatherInfo)
    odds: OddsInfo = field(default_factory=OddsInfo)
    race_url: str = ""


class KeirinScraper:
    """ç«¶è¼ªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v2.1 - KEIRIN.JPå¯¾å¿œ"""
    
    # KEIRIN.JPï¼ˆå…¬å¼ï¼‰
    BASE_URL = "https://keirin.jp"
    
    VELODROME_CODES = {
        "å‡½é¤¨": "01", "é’æ£®": "02", "ã„ã‚ãå¹³": "03", "å¼¥å½¦": "04",
        "å‰æ©‹": "05", "å–æ‰‹": "06", "å®‡éƒ½å®®": "07", "å¤§å®®": "08",
        "è¥¿æ­¦åœ’": "09", "äº¬ç‹é–£": "10", "ç«‹å·": "11", "æ¾æˆ¸": "12",
        "åƒè‘‰": "13", "å·å´": "14", "å¹³å¡š": "15", "å°ç”°åŸ": "16",
        "ä¼Šæ±": "17", "é™å²¡": "18", "åå¤å±‹": "19", "å²é˜œ": "20",
        "å¤§å£": "21", "è±Šæ©‹": "22", "å¯Œå±±": "23", "æ¾é˜ª": "24",
        "å››æ—¥å¸‚": "25", "ç¦äº•": "26", "å¥ˆè‰¯": "27", "å‘æ—¥ç”º": "28",
        "å’Œæ­Œå±±": "29", "å²¸å’Œç”°": "30", "ç‰é‡": "31", "åºƒå³¶": "32",
        "é˜²åºœ": "33", "é«˜æ¾": "34", "å°æ¾å³¶": "35", "é«˜çŸ¥": "36",
        "æ¾å±±": "37", "å°å€‰": "38", "ä¹…ç•™ç±³": "39", "æ­¦é›„": "40",
        "ä½ä¸–ä¿": "41", "åˆ¥åºœ": "42", "ç†Šæœ¬": "43"
    }
    
    # ã‚³ãƒ¼ãƒ‰â†’åå‰ã®é€†å¼•ã
    CODE_TO_NAME = {v: k for k, v in VELODROME_CODES.items()}
    
    BANK_TYPES = {
        "33": ["å‰æ©‹", "å°å€‰"],
        "500": ["å®‡éƒ½å®®", "å¤§å®®", "äº¬ç‹é–£"],
    }
    
    OUTDOOR_BANKS = [
        "å‡½é¤¨", "é’æ£®", "ã„ã‚ãå¹³", "å¼¥å½¦", "å–æ‰‹", "å®‡éƒ½å®®",
        "åƒè‘‰", "å·å´", "å¹³å¡š", "å°ç”°åŸ", "é™å²¡", "è±Šæ©‹",
        "å¯Œå±±", "ç¦äº•", "å¥ˆè‰¯", "å’Œæ­Œå±±", "å²¸å’Œç”°", "ç‰é‡",
        "åºƒå³¶", "é˜²åºœ", "é«˜æ¾", "å°æ¾å³¶", "é«˜çŸ¥", "æ¾å±±",
        "å°å€‰", "ä¹…ç•™ç±³", "æ­¦é›„", "ä½ä¸–ä¿", "åˆ¥åºœ", "ç†Šæœ¬"
    ]
    
    def __init__(self, timeout: int = 30, use_system_proxy: bool = False):
        env_proxy_flag = os.getenv("USE_SYSTEM_PROXY", "").lower() in ("1", "true", "yes")
        use_system_proxy = use_system_proxy or env_proxy_flag

        self.session = requests.Session()
        # CIç’°å¢ƒãªã©ã§ãƒ—ãƒ­ã‚­ã‚·çµŒç”±ã«ãªã‚‹ã¨403ãŒè¿”ã£ã¦ã—ã¾ã†ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ãŸã‚ã€
        # æ˜ç¤ºçš„ã«ç„¡åŠ¹åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ use_system_proxy=True ã§åˆ‡ã‚Šæ›¿ãˆï¼‰
        if not use_system_proxy:
            self.session.trust_env = False
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ja,en-US;q=0.7,en;q=0.3",
        })
        self.timeout = timeout
        self._proxy_retry_used = False

    def _has_system_proxy(self) -> bool:
        return any(os.getenv(k) for k in ("HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy"))
    
    def _get_bank_type(self, velodrome: str) -> str:
        for bank_type, velodromes in self.BANK_TYPES.items():
            if velodrome in velodromes:
                return bank_type
        return "400"
    
    def _is_outdoor(self, velodrome: str) -> bool:
        return velodrome in self.OUTDOOR_BANKS
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def _fetch_page(self, url: str) -> Optional[BeautifulSoup]:
        """ãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        logger.info(f"Fetching: {url}")
        time.sleep(1.5)
        
        try:
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            response.encoding = response.apparent_encoding or 'utf-8'
            logger.info(f"Response status: {response.status_code}, length: {len(response.text)}")
            return BeautifulSoup(response.text, "lxml")
        except requests.exceptions.ProxyError as e:
            logger.error("ProxyError: keirin.jp ã¸ã®åˆ°é”ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã¾ã™ã€‚use_system_proxy=True ã‚‚è©¦ã—ã¦ãã ã•ã„ã€‚")
            logger.debug(f"Proxy error detail: {e}")
            if not self.session.trust_env and not self._proxy_retry_used and self._has_system_proxy():
                logger.info("Retrying with system proxy settings from environment")
                self.session.trust_env = True
                self._proxy_retry_used = True
                return self._fetch_page(url)
            return None
        except requests.exceptions.ConnectionError as e:
            logger.error("ConnectionError: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ©ç”¨ã—ã¦ãã ã•ã„ã€‚")
            logger.debug(f"Connection error detail: {e}")
            if not self.session.trust_env and not self._proxy_retry_used and self._has_system_proxy():
                logger.info("Retrying with system proxy settings from environment")
                self.session.trust_env = True
                self._proxy_retry_used = True
                return self._fetch_page(url)
            return None
        except Exception as e:
            logger.error(f"Fetch error: {e}")
            return None
    
    def get_race_schedule(self, date: Optional[datetime] = None) -> List[Dict]:
        """æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
        if date is None:
            date = datetime.now()
        
        date_str = date.strftime("%Y%m%d")
        
        # KEIRIN.JP ã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰é–‹å‚¬æƒ…å ±ã‚’å–å¾—
        url = f"{self.BASE_URL}/pc/top/"
        logger.info(f"Getting race schedule for {date_str}")
        
        soup = self._fetch_page(url)
        if not soup:
            logger.error("Failed to fetch top page")
            return []
        
        races = []
        
        # é–‹å‚¬å ´ã‚’æ¢ã™ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’è©¦ã™ï¼‰
        selectors = [
            ".kaisaiList a",
            ".jyo-list a", 
            "a[href*='/pc/dfw/dataplaza/guest/raceindex']",
            ".stadium a",
            ".race-link",
        ]
        
        links = []
        for selector in selectors:
            links = soup.select(selector)
            if links:
                logger.info(f"Found {len(links)} links with selector: {selector}")
                break
        
        if not links:
            # å…¨ã¦ã®ãƒªãƒ³ã‚¯ã‹ã‚‰ç«¶è¼ªå ´ã‚’æ¢ã™
            logger.info("Trying to find velodrome links from all anchors")
            all_links = soup.find_all("a", href=True)
            for link in all_links:
                href = link.get("href", "")
                text = link.get_text(strip=True)
                # ç«¶è¼ªå ´åã‚’å«ã‚€ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                for velo_name in self.VELODROME_CODES.keys():
                    if velo_name in text or velo_name in href:
                        links.append(link)
                        break
            logger.info(f"Found {len(links)} velodrome links from all anchors")
        
        seen_velodromes = set()
        
        for link in links:
            href = link.get("href", "")
            text = link.get_text(strip=True)
            
            # ç«¶è¼ªå ´åã‚’ç‰¹å®š
            velodrome = None
            for velo_name in self.VELODROME_CODES.keys():
                if velo_name in text:
                    velodrome = velo_name
                    break
            
            if not velodrome:
                continue
            
            if velodrome in seen_velodromes:
                continue
            seen_velodromes.add(velodrome)
            
            # ãƒ¬ãƒ¼ã‚¹URLã‚’æ§‹ç¯‰
            if href.startswith("http"):
                race_url = href
            elif href.startswith("/"):
                race_url = self.BASE_URL + href
            else:
                race_url = self.BASE_URL + "/" + href
            
            races.append({
                "velodrome": velodrome,
                "velodrome_code": self.VELODROME_CODES.get(velodrome, "00"),
                "url": race_url,
                "date": date_str
            })
            logger.info(f"Found race: {velodrome}")
        
        logger.info(f"Total races found: {len(races)}")
        return races
    
    def get_race_detail(self, race_url: str, race_number: int = 11) -> Optional[RaceInfo]:
        """ãƒ¬ãƒ¼ã‚¹è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        logger.info(f"Getting race detail from: {race_url}")
        
        soup = self._fetch_page(race_url)
        if not soup:
            logger.error("Failed to fetch race page")
            return None
        
        # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ç«¶è¼ªå ´åã‚’å–å¾—
        velodrome = "ä¸æ˜"
        title = soup.find("title")
        if title:
            title_text = title.get_text()
            for velo_name in self.VELODROME_CODES.keys():
                if velo_name in title_text:
                    velodrome = velo_name
                    break
        
        # é¸æ‰‹æƒ…å ±ã‚’å–å¾—ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ï¼‰
        racers = []
        
        # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        tables = soup.find_all("table")
        for table in tables:
            rows = table.find_all("tr")
            for row in rows:
                cells = row.find_all(["td", "th"])
                if len(cells) >= 3:
                    # æ ç•ªã‚’æ¢ã™
                    first_cell = cells[0].get_text(strip=True)
                    if first_cell.isdigit() and 1 <= int(first_cell) <= 9:
                        waku = int(first_cell)
                        name = cells[1].get_text(strip=True) if len(cells) > 1 else f"é¸æ‰‹{waku}"
                        
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        if not any(r.waku == waku for r in racers):
                            racer = Racer(
                                waku=waku,
                                name=name[:10],  # åå‰ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚‹
                                rank="A1",
                                score=100.0
                            )
                            racers.append(racer)
        
        # é¸æ‰‹ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        if len(racers) < 9:
            logger.warning(f"Only found {len(racers)} racers, using demo data")
            return None
        
        # ãƒ©ã‚¤ãƒ³ç·¨æˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        line_formations = [
            LineFormation([1, 2, 4], "å…ˆè¡Œ"),
            LineFormation([3, 7], "æ²ã‚Š"),
            LineFormation([5, 8, 9], "è¿½è¾¼"),
        ]
        
        # å¤©å€™
        weather = WeatherInfo(
            weather="æ™´" if self._is_outdoor(velodrome) else "å±‹å†…",
            wind_direction="åŒ—" if self._is_outdoor(velodrome) else "ãªã—",
            wind_speed=2.0 if self._is_outdoor(velodrome) else 0.0
        )
        
        race_info = RaceInfo(
            race_id=f"{velodrome}_{race_number}_{datetime.now().strftime('%Y%m%d')}",
            velodrome=velodrome,
            velodrome_code=self.VELODROME_CODES.get(velodrome, "00"),
            race_number=race_number,
            race_grade="FII",
            race_type="äºˆé¸",
            distance=2000,
            bank_type=self._get_bank_type(velodrome),
            racers=racers,
            line_formations=line_formations,
            race_datetime=datetime.now(),
            deadline=datetime.now(),
            weather=weather,
            odds=OddsInfo(),
            race_url=race_url
        )
        
        logger.info(f"Created race info: {velodrome} {race_number}R with {len(racers)} racers")
        return race_info
    
    def get_race_result(self, race_url: str) -> Optional[Dict]:
        """ãƒ¬ãƒ¼ã‚¹çµæœã‚’å–å¾—"""
        logger.info(f"Getting race result from: {race_url}")
        
        soup = self._fetch_page(race_url)
        if not soup:
            return None
        
        result = {
            "finish_order": [],
            "winning_pattern": "",
            "payouts": {}
        }
        
        # ç€é †ã‚’æ¢ã™
        # TODO: å®Ÿè£…
        
        return result


def create_demo_race_info() -> RaceInfo:
    """ãƒ‡ãƒ¢ç”¨ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    racers = [
        Racer(1, "å±±ç”°å¤ªéƒ", "12345", 32, "åŸ¼ç‰", "S1", 117.5, "3.92", 
              "ä»Šæ—¥ã¯å…ˆè¡Œä¸€æœ¬ã€‚ä¿¡é ¼ã—ã¦ä»˜ã„ã¦ãã¦ã»ã—ã„", ["1", "2", "1", "3"]),
        Racer(2, "ä½è—¤æ¬¡éƒ", "12346", 28, "åŸ¼ç‰", "S1", 115.2, "3.92", 
              "å±±ç”°ã•ã‚“ã®ç•ªæ‰‹ã‹ã‚‰", ["2", "1", "2", "2"]),
        Racer(3, "éˆ´æœ¨ä¸‰éƒ", "12347", 35, "ç¾¤é¦¬", "S2", 112.3, "3.93", 
              "è‡ªåŠ›ã§å‹è² ã™ã‚‹", ["3", "4", "2", "1"]),
        Racer(4, "ç”°ä¸­å››éƒ", "12348", 30, "æ±äº¬", "A1", 108.7, "3.92", 
              "ä½ç½®å–ã‚Šã‚’å¤§äº‹ã«ã—ãŸã„", ["4", "3", "5", "2"]),
        Racer(5, "ä¼Šè—¤äº”éƒ", "12349", 26, "ç¥å¥ˆå·", "A1", 110.1, "3.92", 
              "è„šã‚’æºœã‚ã¦ç›´ç·šå‹è² ", ["2", "2", "3", "4"]),
        Racer(6, "æ¸¡è¾ºå…­éƒ", "12350", 33, "é™å²¡", "A2", 105.4, "3.93", 
              "æ²ã‚Šä¸€ç™ºç‹™ã„", ["5", "6", "4", "3"]),
        Racer(7, "ä¸­æ‘ä¸ƒéƒ", "12351", 29, "æ„›çŸ¥", "S2", 113.8, "3.92", 
              "éˆ´æœ¨ã•ã‚“ã«ä»˜ã„ã¦ã„ã", ["3", "2", "2", "1"]),
        Racer(8, "å°æ—å…«éƒ", "12352", 31, "å¤§é˜ª", "A1", 107.2, "3.92", 
              "å±•é–‹æ¬¡ç¬¬ã§å‹•ã", ["4", "5", "3", "5"]),
        Racer(9, "å±±æœ¬ä¹éƒ", "12353", 27, "ç¦å²¡", "A2", 104.9, "3.93", 
              "å¾Œæ–¹å¾…æ©Ÿã§å·®ã—ç‹™ã„", ["6", "4", "5", "4"]),
    ]
    
    line_formations = [
        LineFormation([1, 2, 4], "å…ˆè¡Œ", "é–¢æ±ãƒ©ã‚¤ãƒ³"),
        LineFormation([3, 7], "æ²ã‚Š", "åŒ—é–¢æ±ãƒ©ã‚¤ãƒ³"),
        LineFormation([5, 8], "è¿½è¾¼", "å—é–¢æ±ãƒ©ã‚¤ãƒ³"),
        LineFormation([6, 9], "æ²ã‚Š", "æ··æˆãƒ©ã‚¤ãƒ³"),
    ]
    
    weather = WeatherInfo(
        weather="æ™´",
        temperature=18.0,
        humidity=45.0,
        wind_direction="åŒ—",
        wind_speed=2.5,
        track_condition="è‰¯"
    )
    
    odds = OddsInfo(
        sanrentan={"1-2-4": 8.5, "1-2-7": 12.3, "1-4-2": 15.6, "2-1-4": 18.2, "3-7-1": 45.0},
        nirentan={"1-2": 3.2, "1-4": 5.8, "2-1": 4.5, "3-7": 12.0},
        wide={"1-2": 1.5, "1-4": 2.3, "2-4": 3.1}
    )
    
    return RaceInfo(
        race_id="maebashi_11_20241216",
        velodrome="å‰æ©‹",
        velodrome_code="05",
        race_number=11,
        race_grade="GI",
        race_type="æ±ºå‹",
        distance=2025,
        bank_type="33",
        racers=racers,
        line_formations=line_formations,
        race_datetime=datetime.now(),
        deadline=datetime.now(),
        weather=weather,
        odds=odds,
        race_url="https://keirin.jp/pc/dfw/dataplaza/guest/raceindex?KCD=05"
    )


def create_demo_result() -> Dict:
    """ãƒ‡ãƒ¢ç”¨ã®ãƒ¬ãƒ¼ã‚¹çµæœ"""
    return {
        "finish_order": [1, 2, 4, 7, 3, 5, 8, 6, 9],
        "winning_pattern": "é€ƒã’",
        "payouts": {
            "3é€£å˜": {"amount": 850, "combination": "1-2-4"},
            "3é€£è¤‡": {"amount": 320, "combination": "1-2-4"},
            "2è»Šå˜": {"amount": 320, "combination": "1-2"},
            "2è»Šè¤‡": {"amount": 180, "combination": "1-2"},
            "ãƒ¯ã‚¤ãƒ‰": {"amount": 150, "combination": "1-2"}
        },
        "race_time": "1:52.3",
        "last_3f": "11.2"
    }


if __name__ == "__main__":
    scraper = KeirinScraper()
    
    print("=" * 60)
    print("ç«¶è¼ªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v2.1 - ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    print("\nğŸ“… æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ä¸­...")
    races = scraper.get_race_schedule()
    
    if races:
        print(f"\nâœ… {len(races)}å ´ã®é–‹å‚¬ã‚’ç™ºè¦‹:")
        for race in races:
            print(f"  - {race['velodrome']}")
    else:
        print("\nâš ï¸ ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print("ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
        demo = create_demo_race_info()
        print(f"\nãƒ‡ãƒ¢ãƒ¬ãƒ¼ã‚¹: {demo.velodrome} {demo.race_number}R")
